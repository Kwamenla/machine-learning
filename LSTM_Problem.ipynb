{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF8DGSSAcNQS"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "metadata": {
        "id": "doqDO_JqcZPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "id": "TPLOuLDbcZV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN"
      ],
      "metadata": {
        "id": "eRFVaIrHcZbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Build model Simple RNN')\n",
        "simplernnmodel = Sequential()\n",
        "\n",
        "simplernnmodel.add(Embedding(max_features, 128))\n",
        "simplernnmodel.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "simplernnmodel.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "simplernnmodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "simplernnmodel.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = simplernnmodel.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Simple RNN Test score:', score)\n",
        "print('Simpke RNN Test accuracy:', acc)"
      ],
      "metadata": {
        "id": "UTFFuxjTcZgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SimpleRNN couldn't store past information long ago, and could only consider data connections at short time intervals. Simple RNN Test score: 0.6439893245697021\n",
        "**Simple RNN Test accuracy: 0.7068399786949158**\n",
        "\n",
        "\n",
        "LSTM has a mechanism to store data, and it has become possible to consider the connection of data at long time intervals. Test score: 1.049986720085144\n",
        "**Test accuracy: 0.8082000017166138**\n",
        "\n",
        "GRU is a model that simplifies LSTM. The input gate and the forgetting gate are integrated into one gate as an \"update gate\". GRU Test score: 1.456653118133545\n",
        "**GRU Test accuracy: 0.8036400079727173**"
      ],
      "metadata": {
        "id": "I1268ou9eK6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU"
      ],
      "metadata": {
        "id": "MAQt001ZcZmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Build model GRU')\n",
        "grumodel = Sequential()\n",
        "\n",
        "grumodel.add(Embedding(max_features, 128))\n",
        "grumodel.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "grumodel.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "grumodel.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "grumodel.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = grumodel.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('GRU Test score:', score)\n",
        "print('GRU Test accuracy:', acc)"
      ],
      "metadata": {
        "id": "YqM15P6_cZsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "BkuV25UOcZyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),dtype=np.float)\n",
        "    for i in range(n_samples):\n",
        "        n = np.random.randint(3, 8)\n",
        "        for j in range(n):\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "            w = np.random.randint(2, 4)\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,y_shift - w: y_shift + w, 0] += 1\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,x_shift - w - 1: x_shift + w + 1,y_shift - w - 1: y_shift + w + 1,0] += noise_f * 0.1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,y_shift - w: y_shift + w, 0] += 1\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)"
      ],
      "metadata": {
        "id": "swE6IC0acZ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "x = noisy_movies[index]\n",
        "fig = plt.figure()\n",
        "viewer = fig.add_subplot(111)\n",
        "plt.ion()\n",
        "fig.show()\n",
        "for i in range(len(x)):\n",
        "    viewer.clear()\n",
        "    viewer.imshow(x[i])\n",
        "    plt.pause(.1)\n",
        "    fig.canvas.draw()"
      ],
      "metadata": {
        "id": "qFTGiC1jcaEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),input_shape=(None, 40, 40, 1),padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),activation='sigmoid',padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')"
      ],
      "metadata": {
        "id": "P4q8UP24caZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq.fit(noisy_movies[:100], shifted_movies[:100], batch_size=10,epochs=1, validation_split=0.05)"
      ],
      "metadata": {
        "id": "I8Ae3UOidJFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1004\n",
        "track = noisy_movies[index][:7, ::, ::, ::] \n",
        "track2 = noisy_movies[index][::, ::, ::, ::]\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    ax = fig.add_subplot(121)\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[index][i - 1, ::, ::, 0]\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig('%i_animate.png' % (i + 1))"
      ],
      "metadata": {
        "id": "x_CwHn24dJZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "metadata": {
        "id": "uj2RwzbWdJgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tl74dDyWdnDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   RNN - RNN cells distinguish themselves from the regular neurons in the sense that they have a state and thus can remember information from the past.\n",
        "*   SimpleRNNCell - SimpleRNN Cell class-  A Recurrent neural network can be seen as the repetition of a single cell. \n",
        "*   LSTMCell - Cell class of LSTM layer - LSTM is a one kind of RNN and capable of learning long-term dependencies. LSTM cell consists of three gates including  the forget gate, the input gate and the output gate.\n",
        "*   GRUCell - Cell class of GRU layer - It is similar to LSTM. However it does not have a cell state (Ct). It only has a hidden state(Ht). Due to the simpler architecture, GRUs are faster to train.\n",
        "*   StackedRNNCells - A wrapper that makes the behavior of an RNN cell stack look like a single cell. It is used to implement an efficient stacked RNN.\n",
        "*   CoDNNGRU - Fast GRU implementation backed by cuDNN. -  Can only be run on GPU.\n",
        "*   CuDNNLSTM - Fast LSTM implementation backed by cuDNN - Can only be run on GPU."
      ],
      "metadata": {
        "id": "rSWqS9y-dkaR"
      }
    }
  ]
}