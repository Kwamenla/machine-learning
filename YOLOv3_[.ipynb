{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQR6Y489NSHe"
      },
      "outputs": [],
      "source": [
        "!python train.py -p annotation.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install h5py==2.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYoy6blZOWWi",
        "outputId": "9ec95a52-69f3-4aa1-ee89-69f17b43296d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0.tar.gz (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from h5py==2.10.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from h5py==2.10.0) (1.16.0)\n",
            "Building wheels for collected packages: h5py\n",
            "  Building wheel for h5py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h5py: filename=h5py-2.10.0-cp310-cp310-linux_x86_64.whl size=5619994 sha256=db45c759481b5a4d83fd7a800639535108779e060129269bf2deef66cce12552\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/bc/58/0d0c6056e1339f40188d136cd838c6554d9c17545196dd9110\n",
            "Successfully built h5py\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py -i ./kaggle_simpson_testset -c ./save\\train_20230420-231810_config.pickle"
      ],
      "metadata": {
        "id": "KY25rmvNOWbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./yolo/convert.py ./yolo/yolov3.cfg ./yolo/yolov3.weights ./yolo/model_data/yolo_weights.h5"
      ],
      "metadata": {
        "id": "PCTJkBqCOWhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "annotation_df = pd.read_csv('annotation_rcnn.txt',header=None)\n",
        "print(annotation_df.head())\n",
        "\n",
        "le = LabelEncoder()\n",
        "annotation_df.iloc[:,5] = le.fit_transform(annotation_df.iloc[:,5])"
      ],
      "metadata": {
        "id": "UplmIuFwOWqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting annotation file format\n",
        "rcnn_path = 'annotation_rcnn.txt'\n",
        "yolo_path = 'annotation.txt'\n",
        "n_sample, n_col = annotation_df.shape\n",
        "with open(rcnn_path) as f:\n",
        "    lines = f.readlines() \n",
        "    for i in range(n_sample):\n",
        "        line = lines[i]\n",
        "        split_line = line.split(',') \n",
        "        image_path = split_line[0]\n",
        "        split_line[0] = './' + image_path\n",
        "        split_line[-1] = str(annotation_df.iloc[i,5]) + '\\n'  \n",
        "        with open(yolo_path, mode='a') as out_f:\n",
        "            join_line = ','.join(split_line)  \n",
        "            join_line = join_line.replace('.jpg,','.jpg ')  \n",
        "            out_f.write(join_line)"
      ],
      "metadata": {
        "id": "ApqanbY1OWwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_df = pd.read_csv('annotation.txt',header=None)\n",
        "print(annotation_df.head())\n"
      ],
      "metadata": {
        "id": "P5JNlweVOx7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./yolo/train.py"
      ],
      "metadata": {
        "id": "srW3l-fPOyKD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}